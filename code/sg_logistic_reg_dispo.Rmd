---
title: "BUAN 5510 - Capstone - Logistic Reg -> Dispo Type"
author: "Keith Castelino and Sourabh Gupta"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output:
  html_document:
    number_sections: yes
    theme: united
    toc: yes
    toc_depth: 3
    toc_float: yes
---

```{r setup, include=FALSE}


######### Seach for text ----   Data Cleaning has been completed, now the analysis   ----   ############

knitr::opts_chunk$set(
	fig.width = 8.5,
	# include = FALSE,
	# echo = FALSE,
	message = FALSE,
	warning = FALSE
)

options(tibble.print_max = 40, tibble.print_min = 25)

```

# Prepare your environment

Following needs to be done in order to prepare your environment:

+ Clean environment of all variables, functions and packages
+ Load packages required for analysis (only those that are required)
+ Set colour preferences for graphs
+ Load custom functions

Read in the raw data, as is required.

```{r echo = FALSE, message = FALSE, warning = FALSE, include = FALSE}

# Clear environment of variables and functions
rm(list = ls(all = TRUE)) 

# Clear environment of packages
if(is.null(sessionInfo()$otherPkgs) == FALSE) {
  lapply(paste("package:", names(sessionInfo()$otherPkgs), sep=""), 
         detach, character.only = TRUE, unload = TRUE)
}

# # load required libraries (Use install.packages(tidyverse), for example, if needed)
library(tidyverse)
library(caret)
library(ROCR)
# library(readxl)
# library(dlookr)
# library(janitor)
# library(stringr)
# library(lubridate)
# library(naniar)
# library(zoo)
# library(birk)
# library(scales)
# library(doBy)
library(caTools)
library(car)
# Load the package for multinomial modeling
library(nnet)

```

## Summary of Dataset being used

```{r}
#loading data
#
# read dfa_by_category dataset exported from EDA R markdown file -- EDA_11_Nov.Rmd
o_dfa_by_category <- read.csv ("../calculated_data/dfa_by_category_eda.csv", header = TRUE)

o_dfa_by_category <- o_dfa_by_category %>%
                        select(-c(X))

# select required columns to be used for modeling with outcome variable -- DFA(Yes/No)
dfa_by_category <- o_dfa_by_category %>%              
  select(c(gender, venue, age, class, is_violent, crime_hist, drug_court, drug_charge, compt_case, le_18, ge_60, dfa, dispo_type))
summary(dfa_by_category)

```

```{r}
## munge the data for modeling

# convert output variable dfa into numerical
# dfa_by_category$dfa <- ifelse(dfa_by_category$dfa=="Yes", 1, 0)

# Remove records where gender is unknown
dfa_by_category <- dfa_by_category %>%
   filter(gender != "Unknown")

# Remove records where venue is other
dfa_by_category <- dfa_by_category %>%
   filter(venue != "Other")

# Remove records where dispo type is NA
dfa_by_category <- dfa_by_category %>%
   filter(!is.na(dispo_type))

# # remove the records where seriousness is empty/NA
# dfa_by_category <- dfa_by_category[!is.na(dfa_by_category$seriousness),]

dfa_by_category <- droplevels(dfa_by_category)
# # 
dfa_by_category$dfa <- as.factor(dfa_by_category$dfa)

## make CLass GM as reference variable
dfa_by_category$class <- relevel(dfa_by_category$class,"GM")

# #
is.factor(dfa_by_category$gender)
is.factor(dfa_by_category$venue)
is.factor(dfa_by_category$class)
is.factor(dfa_by_category$crime_hist)
is.factor(dfa_by_category$total_dfa)
is.factor(dfa_by_category$dfa)
is.factor(dfa_by_category$dispo_type)

is.factor(dfa_by_category$age)


```

## Split the dataset into train test

```{r}
# Split the dataset into train and test
set.seed(123)   #  set seed to ensure you always have same random numbers generated

# feed in your response variable as a vector to get the expected split
sample = sample.split(dfa_by_category$dispo_type,SplitRatio = 0.8) # splits the data in the ratio mentioned in SplitRatio. After splitting marks these rows as logical TRUE and the the remaining are marked as logical FALSE

train =subset(dfa_by_category, sample ==TRUE) # creates a training dataset named train1 with rows which are marked as TRUE
test  =subset(dfa_by_category, sample ==FALSE)

```

## Build Multinomail model

```{r}
# build model for DFA
# we will use GLM function with argument family = binomial
# Run the model
dispo_type_logistic <- multinom(dispo_type ~ ., data = train)

summary(dispo_type_logistic)
```

```{r}
# anova(dfa_logistic, test="Chisq")
```

```{r}
# library(pscl)
# pR2(dfa_logistic)
```

### Predict values for test dataset

```{r}
### Run the test data thorugh the model
# Use your model to make predictions, in this example newdata = training set, but replace with your test set    
test$pred_dispo_type <- dispo_type_logistic %>%
                          predict(test)

# Model accuracy
mean(test$pred_dispo_type == test$dispo_type, na.rm = TRUE)
```

### Z- values

```{r}
z <- summary(dispo_type_logistic)$coefficients/summary(dispo_type_logistic)$standard.errors
z
```

### P- values

```{r}

# 2-tailed z test
p <- (1 - pnorm(abs(z), 0, 1)) * 2
p
```

### Confusion Matrix

```{r}
caret::confusionMatrix(as.factor(test$pred_dispo_type),as.factor(test$dispo_type))
```


## Build Multinomail model with interaction term dfa * charge_class

```{r}
# build model for DFA
# we will use GLM function with argument family = binomial
# Run the model
dispo_type_logistic_intrac <- multinom(dispo_type ~ . + dfa * class, data = train)

summary(dispo_type_logistic_intrac)
```

### Predict values for test dataset

```{r}
### Run the test data thorugh the model
# Use your model to make predictions, in this example newdata = training set, but replace with your test set    
test$pred_dispo_type <- dispo_type_logistic_intrac %>%
                          predict(test)

# Model accuracy
mean(test$pred_dispo_type == test$dispo_type, na.rm = TRUE)
```

### Z- values

```{r}
z <- summary(dispo_type_logistic_intrac)$coefficients/summary(dispo_type_logistic_intrac)$standard.errors
z
```

### P- values

```{r}

# 2-tailed z test
p <- (1 - pnorm(abs(z), 0, 1)) * 2
p
```

### Confusion Matrix

```{r}
caret::confusionMatrix(as.factor(test$pred_dispo_type),as.factor(test$dispo_type))
```


## Build Logit model with dispo type as Dismissal vs Others

```{r}
### Club GM, M, I, U as one class - GM
dfa_by_category <- dfa_by_category %>%
                    mutate(dispo_type= recode(dispo_type, "c('plea', 'trial')='other'")) %>%
                    drop_na()

# # 
dfa_by_category$dispo_type <- as.factor(dfa_by_category$dispo_type)
```

### Split dataset into Train and Test

```{r}
# Split the dataset into train and test
set.seed(123)   #  set seed to ensure you always have same random numbers generated

# feed in your response variable as a vector to get the expected split
sample = sample.split(dfa_by_category$dispo_type,SplitRatio = 0.8) # splits the data in the ratio mentioned in SplitRatio. After splitting marks these rows as logical TRUE and the the remaining are marked as logical FALSE

train =subset(dfa_by_category, sample ==TRUE) # creates a training dataset named train1 with rows which are marked as TRUE
test  =subset(dfa_by_category, sample ==FALSE)

```

```{r}
# build model for DFA
# we will use GLM function with argument family = binomial
# Run the model
dispo_type_logistic_disvsoth <- glm(dispo_type ~ . , data = train, family = binomial(link="logit"))

summary(dispo_type_logistic_disvsoth)
```


## Predict values for test dataset

```{r}
### Run the test data thorugh the model
# Use your model to make predictions, in this example newdata = training set, but replace with your test set    
test$dispo_type_prob <- predict(dispo_type_logistic_disvsoth, newdata = test, type = "response")
```

## DIfferent Thresholds with Confusion Matrix and other Stats

## 0.4

```{r}
# with threshold 0.4
test$dispo_type_predict <- ifelse(test$dispo_type_prob < 0.4, "dismissal", "other")
test$dispo_type_predict <-as.factor(test$dispo_type_predict)

# print confusion matrix
confusionMatrix(test$dispo_type_predict, test$dispo_type)

#-----------------------------------------------------#
y <- test$dispo_type # logical array of positive / negative cases
predictions <- test$dispo_type_predict # array of predictions

precision <- posPredValue(predictions, y, positive="dismissal")
precision
recall <- sensitivity(predictions, y, positive="dismissal")
recall

F1 <- (2 * precision * recall) / (precision + recall)
F1
#-----------------------------------------------------#

#-----------------------------------------------------#
# library(pROC)
# test$prob = dfa_prob
# g <- roc(dfa ~ prob, data = test)
# plot(g) 
#-----------------------------------------------------#

```

## 0.5

```{r}
# with threshold 0.5
test$dispo_type_predict <- ifelse(test$dispo_type_prob < 0.5, "dismissal", "other")
test$dispo_type_predict <-as.factor(test$dispo_type_predict)

# print confusion matrix
confusionMatrix(test$dispo_type_predict, test$dispo_type)

#-----------------------------------------------------#
y <- test$dispo_type # logical array of positive / negative cases
predictions <- test$dispo_type_predict # array of predictions

precision <- posPredValue(predictions, y, positive="dismissal")
precision
recall <- sensitivity(predictions, y, positive="dismissal")
recall

F1 <- (2 * precision * recall) / (precision + recall)
F1
#-----------------------------------------------------#

```

## 0.6

```{r}
# with threshold 0.6
test$dispo_type_predict <- ifelse(test$dispo_type_prob < 0.6, "dismissal", "other")
test$dispo_type_predict <-as.factor(test$dispo_type_predict)

# print confusion matrix
confusionMatrix(test$dispo_type_predict, test$dispo_type)

#-----------------------------------------------------#
y <- test$dispo_type # logical array of positive / negative cases
predictions <- test$dispo_type_predict # array of predictions

precision <- posPredValue(predictions, y, positive="dismissal")
precision
recall <- sensitivity(predictions, y, positive="dismissal")
recall

F1 <- (2 * precision * recall) / (precision + recall)
F1
#-----------------------------------------------------#

```

## 0.7

```{r}
# with threshold 0.7
test$dispo_type_predict <- ifelse(test$dispo_type_prob < 0.7, "dismissal", "other")
test$dispo_type_predict <-as.factor(test$dispo_type_predict)

# print confusion matrix
confusionMatrix(test$dispo_type_predict, test$dispo_type)

#-----------------------------------------------------#
y <- test$dispo_type # logical array of positive / negative cases
predictions <- test$dispo_type_predict # array of predictions

precision <- posPredValue(predictions, y, positive="dismissal")
precision
recall <- sensitivity(predictions, y, positive="dismissal")
recall

F1 <- (2 * precision * recall) / (precision + recall)
F1
#-----------------------------------------------------#

```





























<!-- ### Predict values for test dataset -->

<!-- ```{r} -->
<!-- ### Run the test data thorugh the model -->
<!-- # Use your model to make predictions, in this example newdata = training set, but replace with your test set     -->
<!-- test$pred_dispo_type <- dispo_type_logistic_disvsoth %>% -->
<!--                           predict(test) -->

<!-- # Model accuracy -->
<!-- mean(test$pred_dispo_type == test$dispo_type, na.rm = TRUE) -->
<!-- ``` -->

<!-- ### Z- values -->

<!-- ```{r} -->
<!-- z <- summary(dispo_type_logistic_intrac)$coefficients/summary(dispo_type_logistic_intrac)$standard.errors -->
<!-- z -->
<!-- ``` -->

<!-- ### P- values -->

<!-- ```{r} -->

<!-- # 2-tailed z test -->
<!-- p <- (1 - pnorm(abs(z), 0, 1)) * 2 -->
<!-- p -->
<!-- ``` -->

<!-- ### Confusion Matrix -->

<!-- ```{r} -->
<!-- caret::confusionMatrix(as.factor(test$pred_dispo_type),as.factor(test$dispo_type)) -->
<!-- ``` -->

<!-- ```{r} -->


<!-- ``` -->

























